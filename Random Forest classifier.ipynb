{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e785108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed84a878",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "561cfdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class node:\n",
    "    \n",
    "    def __init__(self, features = None, threshold = None, left = None, right = None,*, value = None):\n",
    "        \n",
    "        self.features = features\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "        \n",
    "        \n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self, min_sample_split = 2, max_depth = 100, n_features = None ):\n",
    "        \n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.root = None\n",
    "        \n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        self.n_features = X.shape[1] if not self.n_features else min(X.shape[1], self.n_features)\n",
    "        self.root = self._grow_tree(X,Y)\n",
    "        \n",
    "        \n",
    "    def _grow_tree(self, X, Y, depth = 0):\n",
    "        \n",
    "        no_of_samples, no_of_features  = X.shape\n",
    "        no_of_labels = len(np.unique(Y))\n",
    "        \n",
    "        # check stopping criteria\n",
    "        if (depth >= self.max_depth or no_of_labels == 1 or no_of_samples < self.min_sample_split):\n",
    "            \n",
    "            leaf_value = self.most_common_label(Y)\n",
    "            return node(value = leaf_value )\n",
    "        \n",
    "        feature_idx = np.random.choice(no_of_features, self.n_features, replace =False)\n",
    "        \n",
    "        # find the best split\n",
    "        best_feature, best_threshold = self.best_split(X, Y, feature_idx)\n",
    "        \n",
    "        \n",
    "        # create a child node\n",
    "        left_idx, right_idx = self.split(X[:, best_feature], best_threshold)\n",
    "        left = self._grow_tree(X[left_idx, :], Y[left_idx], depth+1)\n",
    "        right = self._grow_tree(X[right_idx, :], Y[right_idx], depth+1)\n",
    "        return node(best_feature, best_threshold, left, right)\n",
    "        \n",
    "        \n",
    "    def best_split(self, X, Y, feature_idx):\n",
    "        \n",
    "        best_gain = -1\n",
    "        split_index, split_threshold = None, None\n",
    "        \n",
    "        for feat in feature_idx:\n",
    "            \n",
    "            X_column = X[: , feat]\n",
    "            thresholds = np.unique(X_column)\n",
    "            \n",
    "            for thr in thresholds:\n",
    "                gain = self.information_gain(Y, X_column, thr)\n",
    "                \n",
    "                if(gain > best_gain):\n",
    "                    best_gain = gain\n",
    "                    split_index = feat\n",
    "                    split_threshold = thr\n",
    "                    \n",
    "        return split_index, split_threshold\n",
    "    \n",
    "    def information_gain(self, Y, X_column, threshold):\n",
    "        \n",
    "        # parent entropy\n",
    "        parent_entropy = self.entropy(Y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # create children\n",
    "        left_idx, right_idx = self.split(X_column, threshold)\n",
    "        \n",
    "        if (len(left_idx) == 0) or (len(right_idx) == 0):\n",
    "            return 0\n",
    "        \n",
    "        # calculate the weighted entropy of children\n",
    "        n = len(Y)\n",
    "        n_l, n_r = len(left_idx), len(right_idx)\n",
    "        e_l, e_r = self.entropy(Y[left_idx]), self.entropy(Y[right_idx])\n",
    "        child_entropy = (n_l/n)*e_l + (n_r/n)*e_r\n",
    "        \n",
    "        \n",
    "        # calculate information gain\n",
    "        info_gain = parent_entropy - child_entropy\n",
    "        return info_gain\n",
    "    \n",
    "    \n",
    "      \n",
    "    def split(self, X_column, split_thresh):\n",
    "        \n",
    "        left_idx = np.argwhere(X_column <= split_thresh).flatten()\n",
    "        right_idx = np.argwhere(X_column > split_thresh).flatten()\n",
    "        return left_idx, right_idx\n",
    "        \n",
    "    \n",
    "    def entropy(self, Y):\n",
    "        \n",
    "        hist = np.bincount(Y)\n",
    "        ps = hist/len(Y)\n",
    "        return -np.sum([p*np.log(p) for p in ps if p>0])\n",
    "        \n",
    "        \n",
    "    \n",
    "    def most_common_label(self, Y):\n",
    "        counter = Counter(Y)\n",
    "        value = counter.most_common(1)[0][0]\n",
    "        return value\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self.traverse_tree(x, self.root) for x in X])\n",
    "    \n",
    "    def traverse_tree(self, x, node):\n",
    "        \n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "          \n",
    "        \n",
    "        if x[node.features]<=node.threshold:\n",
    "            return self.traverse_tree(x, node.left)\n",
    "        return self.traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c14ab",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d400716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \n",
    "    def __init__(self, n_trees = 10, max_depth = 10, min_sample_split = 2, n_feature = None):\n",
    "        \n",
    "        # initializing variables\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.n_feature = n_feature\n",
    "        self.trees= []\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        self.trees = [] # creating an empty list to store all of the trees\n",
    "        for i in range(self.n_trees):\n",
    "            \n",
    "            # Calling decision trees class to create tree\n",
    "            tree = DecisionTree(min_sample_split=self.min_sample_split, max_depth = self.max_depth, n_features = self.n_feature)\n",
    "            \n",
    "            # Function for random samples with replacement\n",
    "            X_sample, Y_sample = self.bootstrap_sample(X,Y) \n",
    "            \n",
    "            # Creating a tree for one particular sample\n",
    "            tree.fit(X_sample,Y_sample) \n",
    "            \n",
    "            # adding the tree in the list\n",
    "            self.trees.append(tree)  \n",
    "            \n",
    "    def bootstrap_sample(self, X,Y):\n",
    "        \n",
    "        # Choosing random index numbers from the data\n",
    "        n_shape = X.shape[0]\n",
    "        sample_idx = np.random.choice(n_shape, n_shape, replace = True)\n",
    "        \n",
    "        # return the sample data through the chosen indexes\n",
    "        return X[sample_idx], Y[sample_idx]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def most_common_label(self, y):  \n",
    "        counter = Counter(y)\n",
    "        most_common_val = counter.most_common(1)[0][0]\n",
    "        return most_common_val\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        #predictiong y values for each X rows from each trees and then storing them in arrays\n",
    "        predict = np.array([tree.predict(X) for tree in self.trees])\n",
    "        \n",
    "        #Result of previous computation [[tree1 prediction], [tree2 prediction]...] = [[X1,X2,X3,X4], [X1,X2,X3,X4]...] \n",
    "        \n",
    "        #Now changing the axes of our array to get all the predictions for one X the first list\n",
    "        predict1 = np.swapaxes(predict, 0,1)\n",
    "        \n",
    "         #Result: [[X1,X1],[X2,X2],[X3,X3],[X4,X4]]\n",
    "        \n",
    "        # predicting most common y value for each array\n",
    "        label_prediction = np.array([self.most_common_label(p) for p in predict1])\n",
    "        \n",
    "        return label_prediction\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "417bea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "649fa8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210526315789473"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "Y = breast_cancer.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1234)\n",
    "\n",
    "def accuracy(y_pred, y_test):\n",
    "    \n",
    "    accuracy = np.sum(y_pred == y_test)/len(y_test)\n",
    "    return accuracy\n",
    "\n",
    "model = RandomForest(n_trees = 20)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predictions_data = model.predict(X_test)\n",
    "accuracy(predictions_data, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d2e951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
